{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data and perform basic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Load the data in using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_act = pd.read_csv('../data/act.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.set_index('Unnamed: 0', inplace=True)\n",
    "#df = df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "df_act.set_index('State', drop= True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_act.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_act.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sat = pd.read_csv('../data/sat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sat.set_index('State', drop= True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sat.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Print the first ten rows of each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_act.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Describe in words what each variable (column) is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ACT table:\n",
    "    - State is the individual states around the US\n",
    "    - Participation is the participation rate for the ACT\n",
    "    - English is the score for English\n",
    "    - Math is the score for math\n",
    "    - Reading is the score for reading\n",
    "    - Science is the score for science\n",
    "    - Composite is the average english, math, reading and science \n",
    "\n",
    "SAT table:\n",
    "    - State is the individual states around the US\n",
    "    - Participation is the participation rate for the SAT\n",
    "    - Evidence-Based Reading and Writing is the score for reading and writing\n",
    "    - Math is the score for Math\n",
    "    - Total is the math + R&W score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Does the data look complete? Are there any obvious issues with the observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACT dataframe has an outlier 2.3 in Science for Maryland.  I replaced it with 23.2 from the original data source.\n",
    "\n",
    "SAT dataframe has an outlier 52 in Math for Maryland. I replaced it with 524 from the original data source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Print the types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_act.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sat.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Do any types need to be reassigned? If so, go ahead and do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_act['Participation'] = df_act['Participation'].map(lambda x: float(x[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sat['Participation'] = df_sat['Participation'].map(lambda x: float(x[:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Create a dictionary for each column mapping the State to its respective value for that column. (For example, you should have three SAT dictionaries.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_participation_dict = df_act.to_dict()['Participation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_english_dict = df_act.to_dict()['English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_math_dict = df_act.to_dict()['Math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_reading_dict = df_act.to_dict()['Reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_science_dict = df_act.to_dict()['Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_composite_dict = df_act.to_dict()['Composite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sat_participation_dict = df_sat.to_dict()['Participation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sat_reading_and_writing_dict = df_sat.to_dict()['Evidence-Based Reading and Writing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sat_total_dict = df_sat.to_dict()['Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Create one dictionary where each key is the column name, and each value is an iterable (a list or a Pandas Series) of all the values in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{k:v for k,v in zip(df_act.columns,df_act.values.transpose())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{k:v for k,v in zip(df_sat.columns,df_sat.values.transpose())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Merge the dataframes on the state column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merge = df_act.merge(df_sat, on='State')\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Change the names of the columns so you can distinguish between the SAT columns and the ACT columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge = df_merge.rename(columns={'State':'State',\n",
    "                        'Participation_x': 'Participation_ACT', \n",
    "                         'English': 'English_ACT',\n",
    "                         'Math_x': 'Math_ACT', \n",
    "                        'Reading': 'Reading_ACT', \n",
    "                         'Science': 'Science_ACT',\n",
    "                         'Composite': 'Composite_ACT',\n",
    "                         'Participation_y': 'Participation_SAT',\n",
    "                         'Evidence-Based Reading and Writing': 'Evidence-Based Reading and Writing_SAT',\n",
    "                         'Math_y': 'Math_SAT',\n",
    "                         'Total': 'Total_SAT'})\n",
    "\n",
    "\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Print the minimum and maximum of each numeric column in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Write a function using only list comprehensions, no loops, to compute standard deviation. Using this function, calculate the standard deviation of each numeric column in both data sets. Add these to a list called `sd`.\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sd = []\n",
    "\n",
    "def standard_dev(col_name):\n",
    "    lst = df_merge[col_name]\n",
    "    mean = sum(lst)/len(lst)\n",
    "    return (sum([(num - mean) ** 2 for num in lst])/len(lst)) ** 0.5\n",
    "\n",
    "sd.append(list(standard_dev(col_name) for col_name in df_merge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Manipulate the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Turn the list `sd` into a new observation in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sd = pd.DataFrame(sd, columns = df_merge.columns, index = ['SD'])\n",
    "df_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge.append(df_sd, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Sort the dataframe by the values in a numeric column (e.g. observations descending by SAT participation rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_math_sort = df_merge.sort_values(['Math_ACT'], ascending = True)\n",
    "df_math_sort.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Use a boolean filter to display only observations with a score above a certain threshold (e.g. only states with a participation rate above 50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge[(df_merge['Math_ACT'] > 21) & (df_act['Participation'] > 65)].iloc[:,[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 16. Using MatPlotLib and PyPlot, plot the distribution of the Rate columns for both SAT and ACT using histograms. (You should have two histograms. You might find [this link](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes) helpful in organizing one plot above the other.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))\n",
    "ax[0].set_xlabel('Participation (%)')\n",
    "ax[1].set_xlabel('Participation (%)')\n",
    "\n",
    "df_merge['Participation_ACT'].plot(ax = ax[0], title = 'ACT Participation Rate', kind='hist')\n",
    "df_merge['Participation_SAT'].plot(ax = ax[1], title = 'SAT Participation Rate', kind='hist', color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 17. Plot the Math(s) distributions from both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(nrows = 1, ncols = 3, figsize = (15,5))\n",
    "ax[0].set_xlabel('Scores')\n",
    "ax[1].set_xlabel('Scores')\n",
    "ax[2].set_xlabel('Scores')\n",
    "\n",
    "df_merge['Math_ACT'].plot(ax = ax[0], title = 'ACT Math', kind='hist')\n",
    "df_merge['Science_ACT'].plot(ax = ax[1], title = 'ACT Science', kind='hist', color='orange')\n",
    "df_merge['Math_SAT'].plot(ax = ax[2], title = 'SAT Math', kind='hist', color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. Plot the Verbal distributions from both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(nrows = 1, ncols = 3, figsize = (15,5))\n",
    "ax[0].set_xlabel('Scores')\n",
    "ax[1].set_xlabel('Scores')\n",
    "ax[2].set_xlabel('Scores')\n",
    "\n",
    "df_merge['English_ACT'].plot(ax = ax[0], title = 'ACT English', kind='hist')\n",
    "df_merge['Reading_ACT'].plot(ax = ax[1], title = 'ACT Reading', kind='hist', color='orange')\n",
    "df_merge['Evidence-Based Reading and Writing_SAT'].plot(ax = ax[2], title = 'SAT Reading and Writing', kind='hist', color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. When we make assumptions about how data are distributed, what is the most common assumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The most common assumption is the assumption of normality.  Most parametric tests require that the assumption of \n",
    "normality be met.  Normality means that the distribution of the test is normally distributed with 0 mean, with 1 \n",
    "standard deviation and a symmetric bell shaped curve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20. Does this assumption hold true for any of our columns? Which?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "ACT Science is the closest to a normal distribution. None of the other columns have a normal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. Plot some scatterplots examining relationships between all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(nrows = 2, ncols = 2, figsize = (12,12))\n",
    "\n",
    "df_merge.plot(x='Participation_ACT', y='English_ACT', title = 'Participation Rate ACT & English ACT', \n",
    "              kind='scatter', ax = ax[0][0])\n",
    "df_merge.plot(x='Participation_ACT', y='Math_ACT', title = 'Participation Rate ACT & Math ACT', \n",
    "              kind='scatter', ax = ax[0][1])\n",
    "df_merge.plot(x='Participation_ACT', y='Reading_ACT', title = 'Participation Rate ACT & Reading ACT', \n",
    "              kind='scatter', ax = ax[1][0])\n",
    "df_merge.plot(x='Participation_ACT', y='Science_ACT', title = 'Participation Rate ACT & Science ACT', \n",
    "              kind='scatter', ax = ax[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))\n",
    "\n",
    "df_merge.plot(x='Participation_SAT', y='Evidence-Based Reading and Writing_SAT', \n",
    "              title = 'Participation Rate SAT & Reading and Writing SAT', kind='scatter', ax = ax[0])\n",
    "df_merge.plot(x='Participation_SAT', y='Math_SAT', \n",
    "              title = 'Participation Rate SAT & Math SAT', kind='scatter', ax = ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.plot(x='Participation_ACT', y='Participation_SAT', \n",
    "              title = 'Participation Rate ACT & Participation Rate SAT', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Are there any interesting relationships to note?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The ACT participation rate has a strong negative correlation to all ACT variables.  \n",
    "\n",
    "The SAT participation rate has a strong negative correlation to all SAT variables.\n",
    "\n",
    "THE ACT participation rate and the SAT participation rate are negatively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Create box plots for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(nrows = 2, ncols = 5, figsize = (15,10))\n",
    "\n",
    "sns.boxplot(df_merge['Participation_ACT'], ax = ax[0][0])\n",
    "sns.boxplot(df_merge['English_ACT'], ax = ax[0][1])\n",
    "sns.boxplot(df_merge['Math_ACT'], ax = ax[0][2])\n",
    "sns.boxplot(df_merge['Reading_ACT'], ax = ax[0][3])\n",
    "sns.boxplot(df_merge['Science_ACT'], ax = ax[0][4])\n",
    "sns.boxplot(df_merge['Composite_ACT'], ax = ax[1][0])\n",
    "sns.boxplot(df_merge['Participation_SAT'], ax = ax[1][1])\n",
    "sns.boxplot(df_merge['Evidence-Based Reading and Writing_SAT'], ax = ax[1][2])\n",
    "sns.boxplot(df_merge['Math_SAT'], ax = ax[1][3])\n",
    "sns.boxplot(df_merge['Total_SAT'], ax = ax[1][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BONUS: Using Tableau, create a heat map for each variable using a map of the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Done on Tableau.  Saved to an 'Images' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Summarize each distribution. As data scientists, be sure to back up these summaries with statistics. (Hint: What are the three things we care about when describing distributions?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "| Column               | Mean              | Standard Deviation   | Variance          | Skew\n",
    "| :-------------       |:-------------:    | :--------------:     | :--------------:  | :--------------:\n",
    "| Participation_ACT    | 65.25             |  31.82               |  1033.03          |  Left skew \n",
    "| English_ACT          | 20.93             |  2.33                |  5.54             |  Right skew\n",
    "| Math_ACT             | 21.18             |  1.96                |  3.93             |  Right skew \n",
    "| Reading_ACT          | 22.01             |  2.05                |  4.27             |  Right skew\n",
    "| Science_ACT          | 21.45             |  1.72                |  3.03             |  Right skew\n",
    "| Composite_ACT        | 21.52             |  2.00                |  4.08             |  Right skew\n",
    "| Participation_SAT    | 39.80             |  34.93               |  1244.44          |  Right skew\n",
    "| Reading/Writing_SAT  | 569.12            |  45.22               |  2085.47          |  Right skew\n",
    "| Math_SAT             | 556.88            |  46.66               |  2220.43          |  Right skew\n",
    "| Total_SAT            | 1126.10           |  91.58               |  8555.29          |  Right skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Summarize each relationship. Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df_merge.corr(), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACT parcipation rate is negatively correlated to SAT participation. (-0.84)\n",
    "\n",
    "ACT participation rate has a strong negative negative correlation to the ACT subjects. (-0.84, -0.86, -0.87, -0.84)\n",
    "\n",
    "SAT participation rate has a strong negative negative correlation to the SAT subjects. (-0.87, -0.86)\n",
    "\n",
    "ACT participation rate has a strong negative correlation to the ACT composite. (-0.86)\n",
    "\n",
    "SAT participation rate has a strong negative correlation to the SAT total. (-0.87)\n",
    "\n",
    "ACT subjects have a loose negative correlation to the SAT subjects. (in the -0.4 range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Execute a hypothesis test comparing the SAT and ACT participation rates. Use $\\alpha = 0.05$. Be sure to interpret your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$H_0$: The means are equal between the SAT and ACT participation rates.\n",
    "\n",
    "$H_1$: The means are different between the SAT and ACT participation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(df_merge['Participation_SAT'], df_merge['Participation_ACT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values of less than 0.05 are considered small. With a p-value at .00002, it is implied that a significant difference does exist. The p value is also smaller than the alpha so the null hypothesis can be rejected and we can conclude that the alterative hypothesis is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Generate and interpret 95% confidence intervals for SAT and ACT participation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.interval(.95, np.mean(df_merge['Participation_ACT']), np.std(df_merge['Participation_ACT'], \n",
    "                                                ddof=1)/np.sqrt(len(df_merge['Participation_ACT']))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that we are 95% confident that the true mean of the ACT partipation rate falls \n",
    "between 56.4% and 74.1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.interval(.95, np.mean(df_merge['Participation_SAT']), np.std(df_merge['Participation_SAT'], \n",
    "                                                ddof=1)/np.sqrt(len(df_merge['Participation_SAT']))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that we are 95% confident that the true mean of the SAT partipation rate falls \n",
    "between 30.1% and 49.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 28. Given your answer to 26, was your answer to 27 surprising? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I was not surprised because we rejected the null hypothesis and concluded that the alternative hypothesis was true.  This means that the means are different between the SAT and ACT participation rates so there should be no overlap in the confidence interval of the two.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 29. Is it appropriate to generate correlation between SAT and ACT math scores? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df_merge['Math_ACT'], df_merge['Math_SAT'])[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is not appropriate to generate correlation between SAT and ACT math scores because:\n",
    "\n",
    "1. The two tests are graded on different scales, so the correlation between the raw numbers in both tests does not tell us much.\n",
    "\n",
    "2. Some states require students to take the ACT while others require the SAT.  The information in this dataset did not control for the participation differences between these states and that could have significantly affected these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30. Suppose we only seek to understand the relationship between SAT and ACT data in 2017. Does it make sense to conduct statistical inference given the data we have? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It does not make sense to conduct statistical inference given the data we have because the sample consists of the mean results in each category from every state.  This sample does not take into account that a mean score from a state that has a low participation rate cannot be fairly measured against a mean score from a state with a high participation rate.  To be able to conduct statistical inference we would have to get information from a large sample and find a way to control for participation rates."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
